# llm-yara-security
Simple notebook example of using YARA rules to scan both LLM prompt input and output (as well as any other string) using python
